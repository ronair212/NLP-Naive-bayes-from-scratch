{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96da5ff7",
   "metadata": {},
   "source": [
    "# Analysis of Movie Reviews dataset using Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6999ecdd",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb1fa6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "4  Probably my all-time favorite movie, a story o...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.utils import resample,shuffle\n",
    "import string\n",
    "string.punctuation # checking punctuations\n",
    "\n",
    "df = pd.read_csv(\"/Users/rohitnair/Documents/MSDS/6120 NLP/movie_reviews-1.csv\", sep = ',', encoding = 'latin-1', usecols = lambda col: col not in [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3228a6",
   "metadata": {},
   "source": [
    "## Count plot of the output categories: positive or negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14c2879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12474"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_pos = len(df[df['sentiment'] == 'positive'])\n",
    "count_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b963c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12225"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_neg = len(df[df['sentiment'] == 'negative'])\n",
    "count_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26361006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAADiCAYAAABk10GPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAfs0lEQVR4nO3de5wcVZ338c+XBMLNACEBIQMEMKwmuMImsiCKaHwELxBELuERkwD7RBF0va2C+gjqE0FhZQUFQUECIhAjSLgpGAwgC4SJZAkJBKJBCAQyQS7hTuD3/HFOk0qnZ6YzNdM9w3zfr1e/uurUqapT1dX96zrnVJUiAjMzs65ar9kFMDOzvs2BxMzMSnEgMTOzUhxIzMysFAcSMzMrxYHEzMxKcSBpIkknS4rC6zFJv5W0czevJyQdXxifIumgGvkeknR6d667nfLcK+nqDqZfI+m+bl5nZR/vVZW+a07ftzvXty6a/Xk0gqTZkmY0uxx9QXvHQ282sNkFMJ4B9s/DOwHfA2ZJGh0Rz3fTOvYClhTGpwD3Ar+ryvcJ4MluWmdHLgW+LWmLiHiqOEHSFsCHSfuhJ3wL+FgPLburmv15NMLngFebXYg+or3jodfyGUnzrYqIO/Lr18AkYAfgo921grzsJ+rId3dEPNxd6+3ApcAGwME1pn0SWB+4rAfWOxv4qKTde2DZ3a6Bn8daJK0vaUB3LS8iFkbEg921POtdHEh6n7n5fQSApKGSpkl6UtILuYpgbHEGSQdKmivpeUlPSbpT0vsL09+o2pI0GxgDTCpU90zO096oSpF0lKSXJW1eta7ReZ5xhbTxklolvSTpcUk/lLR+exsYEX8D5gATakyeALRWfnQktUiaLmm5pBcl/VVSV89WrgAWAt/sLKOkf5O0IO+Dv0v6Wo08x0t6JO/330kaV11NJukrku6S9IykJyRdLelthemzafLnUSmHpBm5WuWvwEvAtp3ti3rLVatqK1crXitpZX79RtJbC9P/LukbhfHP5GV+oWr/PloYPyaX9UVJKyTdLGl0J9u+g6RLc/4XJN0j6X8XptfzHVyj+jinnSxpRWF8cs73Tkk35uPmfkkHF/LMpp3joTdzIOl9RuT3x/P774D9gK8Ch5M+sz9VfoyU2lNmADcBBwCfAq4BhrSz/M8B9wPXkaq89gKurZHvivz+iar0w4HlpH/3SDos550DHAh8h3Rqfkon23kp8AFJW1USJG0N7JunVVwEbJeX+RFgKjCok2W3J4DvAwdLGtVeJkn/AZxD2vcfz8Pf05rtTJ8AzgJmkvbRPcD5NRbXAvwEGA/8H2AAcJukzfL03vJ5AOwNHAt8nXQsPVPHvqirXNXy8XsbsCHwaWAyMBq4WpJytluB9xVm24cU4KrTbs3L3Af4GfAr0rFyNPDfwGa0Ix9/twPvJn3HDiB9jtsVsv2ODr6DXfBrVh83DwKXSWrJ0+o9HnqXiPCrSS/gZGAFqa1qILAL8CfgWWAbUttJAO8vzLMJ0Aacm8cPAZ7sZD0BHF8YbwUurJHvIeD0wvhVwO+r8iwCfpKHBfwd+GVVnqOBF4EtOyjTNsBrwHGFtOOB14GWQtpzwAHdsK8jL38AsBi4OKfvmqftm8cH53WeVDX/d0nBfUAevwu4tirP2cVl1SjDAGAjYCUwsZd9HrNznrcW0urdFx2Wq7D8GYXxi3OeDQppI/Mx8bE8/hlSG+J6efxhUlB+vLC9KyrHEOmHfu46HhenAM8D27QzvdPvYK3vWBS+34XxyTnf0YW0LYFVwGc7Ox5688tnJM23JakR8lXSF2sn4PCIWAbsAbRFxM2VzJEa4K8B3puT5gOb5VPvD0vapBvLdjkwTtJQAEm7kYLd5Xn6LsD2wHRJAysv0tnRhqQf6Zry9t1M+odXcThwS0QsLaTNA07J1QLbl92giHgNOBU4QrV7x+1F+qH4TY1t2hpoUWo72I30r7KoehxJe+ZqjCdJPxgvAJuS9t266rHPI5sbEY8XxjvdF3WWq5YPAVcCrxeWu4QUPCvVRreSgtm7JI3I6/shMFTSSNIZzJY5H6RjZXdJZ0jaR9IGnWwvwAdJQXBZO9Pr+Q6uqxsKy3qSdObW0n723s+BpPmeIZ1WjyUdTCMi4vo8bRugViP5E+Sqq4hYRKo22Yl0OrxC0q8lDeuGss0kBbhKHe7hwKPAn/P40Px+HauD4aus7iFWrB6o5VLgvUrtIC2kqpVLq/IcTvqHdgbwd0nzVGgP6KKLgMdIVTjVKtu0gDW36U85fTtgGOkMsq1q3jXGc+C7gfTP+TOk7Xs36Ydjwy6Uu6c/j+pjrZ59UU+5ahlK2v+vVr12qiw3IhaSzjjel1/3Rup8MK+Q9jSphxMR8UfgKFJ112zSd+HsTv5cbQm0F0Sgju9gFzxdNf4KXTseeg13/22+VRHR2s60ZcBWNdK3Bv5RGYmIa4Frc737x4D/ItXf12rMrltEPCfpWtIPw3nAYcD0yOffhTJMAe6usYglNdKKfgv8NC9XpGqNNRpkI+JRYLKk9Uj/Dk8GZkraPv+bW2cR8Yqk04DTWV3HX1HZpo9T+wdkEemsYhUpoBRVj+8PbAyMz/9iyf+8u/QD1IDPo/qZEvXsi3rKVcs/SGckv6gxbUVh+M+sDhi35LRK28mGwG0R8fobGxAxDZiW/0gdTPoD8ixwQjvleJIULNpT13cQeJnUE7Goq4Gmz3Eg6d3uBL4jaZ+IuAVA0sakYHFldeaIeAb4tVKPrb2qpxesyz+gy4DLJR1A+rdY7Ja7iPTPc0RE/LzO5RXL+w9JfyAFPAE3tBcc8o/FHZK+Q2pA3YFy11j8nNR7q7o31u2ktoJtc4CuSdI80pnguYXkA6uybURq81lVSDuMtb93veLzqKGufVFHuWqZRapqm9tJwLmV9Bk9A/zfnHYLcBppn51Va6aIaAPOzT2i2u1YkcvxBUlbR+0u8vV+B5cC76iM5D8+H+xgvR3pc2coDiS9WET8QdJtpC/oCaQfzq+SfqBOg9QlkhQ0fk+qrhkJHEqqvmnP/cB+kvbLy1zSwb/7a0n/wM/N+eYUyve6pK8AF0saDFxP+hLsBBwEHBIRL3SymZcCl+ThTxcn5DOsP+RteYDUW+srpIbe+3KeicAFwM4R8fdO1vWGiHhJ0o+AH1SlPy3pZODHknYg/WitR6rz/0BEVHonfR+4QtJPSFU7e7P6QsfKP+SbSA3sv5R0PqlO/6usXbXRmz6PruyLDsvVjpNJPcuulXQB6SxkOPC/SA3Ns3O+W4D/JJ0BVM5I/gxU2rcq7SPkPxlDyNVawO7A+2n/bATSGctE4FZJU4FHSAFhk4j4YT3fwexK4DhJdwN/A/6N1L7TFetyPPQOzW7t788vqnp1tJNnGOmH9CnSv8ObgXcXple6Bz5G6hq5hPTjOKiQp7rX1k7AH0n/8gKYnNMfotBLqJD/VznfKe2U8SOkL/TzpGqEecD/AwbWsQ82yfO9CLylatog0plDpTppBamR852FPJNz2UZ0sp5avWo2JX1R1+ppBRxJuqbnxbzv7wS+XJXn86R/oi+Q2iUOzcvarZBnIvDXvJw7gH+t3s+94fOgqlfVuu6LzspVa/nA20lVmf/Iy15MCkTFXnsDSL3cHqia9748T7HX18dJZxhtpO/CIlIQUSfHxg6kjgFP5c/yf4AJ9X4HC8fStLwtj5PuoHAytXttbVo1b13HQ29+KRfczEqS9C1SddmQiHix2eUxaxRXbZl1QW7MPZHUg+kFUuPv14HzHUSsv3EgMeuaV0hVMxNJV04vA37M6gZhs37DVVtmZlaKL0g0M7NSHEjMzKyUftdGMnTo0BgxYkSzi2Fm1qfMnTt3RUTUvPVSvwskI0aMoLW1vTuSmJlZLZLaveDXVVtmZlaKA4mZmZXiQGJmZqU4kJiZWSkOJGZmVkq/67XVHcb8R0d3aLf+au5pE5tdBLOm8BmJmZmV4kBiZmal9FggkXSBpOWS7i2knSbpfkn3SLpS0uaFaSdKWixpUX4yWCV9jKT5edqZkpTTB0m6PKffKWlET22LmZm1ryfbSC4EfsKaj3y9ETgxIlZJ+gHpeQ5flzSK9Nzu0cC2wB8l7RIRrwHnAFNIT5e7Dtif9AjRY4CnIuJtkiaQngp4eA9uj1mv9/B339nsIlgvtP235/fo8nvsjCQibiE9drKYdkNErMqjdwAteXg8cFlEvBwRS0iP3NxD0jbA4Ii4PdL97i8iPXu6Ms+0PDwDGFc5WzEzs8ZpZhvJ0aQzC4DhwCOFaUtz2vA8XJ2+xjw5OD0DbFlrRZKmSGqV1NrW1tZtG2BmZk0KJJK+CawCLqkk1cgWHaR3NM/aiRHnRcTYiBg7bFjNm1eamVkXNTyQSJoEfBz4VKx+PONSYLtCthbgsZzeUiN9jXkkDSQ97nSNqjQzM+t5DQ0kkvYHvg4cGBEvFCbNBCbknlg7AiOBORGxDFgpac/c/jERuKowz6Q8fAhwU/i5wWZmDddjvbYkXQrsCwyVtBQ4idRLaxBwY24XvyMiPhsRCyRNBxaSqryOyz22AI4l9QDbiNSmUmlXOR+4WNJi0pnIhJ7aFjMza1+PBZKIOKJG8vkd5J8KTK2R3grsWiP9JeDQMmU0M7PyfGW7mZmV4kBiZmalOJCYmVkpDiRmZlaKA4mZmZXiQGJmZqU4kJiZWSkOJGZmVooDiZmZleJAYmZmpTiQmJlZKQ4kZmZWigOJmZmV4kBiZmalOJCYmVkpDiRmZlZKjwUSSRdIWi7p3kLaEEk3Snowv29RmHaipMWSFknar5A+RtL8PO3M/Mhd8mN5L8/pd0oa0VPbYmZm7evJM5ILgf2r0k4AZkXESGBWHkfSKNKjckfnec6WNCDPcw4whfQc95GFZR4DPBURbwPOAH7QY1tiZmbt6rFAEhG3kJ6lXjQemJaHpwEHFdIvi4iXI2IJsBjYQ9I2wOCIuD0iArioap7KsmYA4ypnK2Zm1jiNbiPZOiKWAeT3rXL6cOCRQr6lOW14Hq5OX2OeiFgFPANsWWulkqZIapXU2tbW1k2bYmZm0Hsa22udSUQH6R3Ns3ZixHkRMTYixg4bNqyLRTQzs1oaHUieyNVV5PflOX0psF0hXwvwWE5vqZG+xjySBgKbsXZVmpmZ9bBGB5KZwKQ8PAm4qpA+IffE2pHUqD4nV3+tlLRnbv+YWDVPZVmHADfldhQzM2uggT21YEmXAvsCQyUtBU4CTgWmSzoGeBg4FCAiFkiaDiwEVgHHRcRreVHHknqAbQRcn18A5wMXS1pMOhOZ0FPbYmZm7euxQBIRR7QzaVw7+acCU2uktwK71kh/iRyIzMyseXpLY7uZmfVRDiRmZlaKA4mZmZXiQGJmZqU4kJiZWSkOJGZmVooDiZmZleJAYmZmpTiQmJlZKQ4kZmZWigOJmZmV4kBiZmalOJCYmVkpDiRmZlaKA4mZmZXiQGJmZqU0JZBI+pKkBZLulXSppA0lDZF0o6QH8/sWhfwnSlosaZGk/QrpYyTNz9POzI/jNTOzBmp4IJE0HPgCMDYidgUGkB6TewIwKyJGArPyOJJG5emjgf2BsyUNyIs7B5hCesb7yDzdzMwaqFlVWwOBjSQNBDYGHgPGA9Py9GnAQXl4PHBZRLwcEUuAxcAekrYBBkfE7RERwEWFeczMrEEaHkgi4lHgdOBhYBnwTETcAGwdEctynmXAVnmW4cAjhUUszWnD83B1+lokTZHUKqm1ra2tOzfHzKzfa0bV1haks4wdgW2BTSQd2dEsNdKig/S1EyPOi4ixETF22LBh61pkMzPrQDOqtj4ELImItoh4FbgCeA/wRK6uIr8vz/mXAtsV5m8hVYUtzcPV6WZm1kDNCCQPA3tK2jj3shoH3AfMBCblPJOAq/LwTGCCpEGSdiQ1qs/J1V8rJe2ZlzOxMI+ZmTXIwEavMCLulDQD+AuwCrgbOA/YFJgu6RhSsDk0518gaTqwMOc/LiJey4s7FrgQ2Ai4Pr/MzKyBGh5IACLiJOCkquSXSWcntfJPBabWSG8Fdu32ApqZWd18ZbuZmZVSVyCRNKueNDMz6386rNqStCHpgsGhudtupcvtYFLXXTMz6+c6ayP5DPBFUtCYy+pA8izw054rlpmZ9RUdBpKI+DHwY0mfj4izGlQmMzPrQ+rqtRURZ0l6DzCiOE9EXNRD5TIzsz6irkAi6WJgZ2AeULmGo3KjRDMz68fqvY5kLDAq32XXzMzsDfVeR3Iv8NaeLIiZmfVN9Z6RDAUWSppDugIdgIg4sEdKZWZmfUa9geTkniyEmZn1XfX22rq5pwtiZmZ9U729tlay+qFRGwDrA89HxOCeKpiZmfUN9Z6RvKU4LukgYI+eKJCZmfUtXbr7b0T8Dvhg9xbFzMz6onqrtg4ujK5Huq7E15SYmVndZyQHFF77ASuB8V1dqaTNJc2QdL+k+yTtJWmIpBslPZjftyjkP1HSYkmLJO1XSB8jaX6edmZ+5K6ZmTVQvW0kR3Xzen8M/D4iDpG0AelW9d8AZkXEqZJOAE4Avi5pFDABGE26C/EfJe2SH7d7DjAFuAO4DtgfP27XzKyh6n2wVYukKyUtl/SEpN9KaunKCiUNBvYBzgeIiFci4mnSGc60nG0acFAeHg9cFhEvR8QSYDGwh6RtgMERcXu+dctFhXnMzKxB6q3a+iUwk3RGMBy4Oqd1xU5AG/BLSXdL+oWkTYCtI2IZQH7fKucfDjxSmH9pThueh6vT1yJpiqRWSa1tbW1dLLaZmdVSbyAZFhG/jIhV+XUhMKyL6xwI/AtwTkTsDjxPqsZqT612j+ggfe3EiPMiYmxEjB02rKvFNjOzWuoNJCskHSlpQH4dCTzZxXUuBZZGxJ15fAYpsDyRq6vI78sL+bcrzN8CPJbTW2qkm5lZA9UbSI4GDgMeB5YBhwBdaoCPiMeBRyT9U04aBywkVZ1NymmTgKvy8ExggqRBknYERgJzcvXXSkl75t5aEwvzmJlZg9R708bvAZMi4ikASUOA00kBpis+D1ySe2z9jRSU1gOmSzoGeBg4FCAiFkiaTgo2q4Djco8tgGOBC4GNSL213GPLzKzB6g0k/1wJIgAR8Q9Ju3d1pRExj3RRY7Vx7eSfCkytkd4K7NrVcpiZWXn1Vm2tV3WB4BDqD0JmZvYmVm8w+E/gvyXNIPWMOowaZwhmZtb/1Htl+0WSWkk3ahRwcEQs7NGSmZlZn1B39VQOHA4eZma2hi7dRt7MzKzCgcTMzEpxIDEzs1IcSMzMrBQHEjMzK8WBxMzMSnEgMTOzUhxIzMysFAcSMzMrxYHEzMxKcSAxM7NSmhZI8iN775Z0TR4fIulGSQ/m9+Jt60+UtFjSIkn7FdLHSJqfp52Zn5RoZmYN1Mwzkn8H7iuMnwDMioiRwKw8jqRRwARgNLA/cLakAXmec4AppMfvjszTzcysgZoSSCS1AB8DflFIHg9My8PTgIMK6ZdFxMsRsQRYDOwhaRtgcETcHhEBXFSYx8zMGqRZZyT/BXwNeL2QtnVELAPI71vl9OHAI4V8S3Pa8DxcnW5mZg3U8EAi6ePA8oiYW+8sNdKig/Ra65wiqVVSa1tbW52rNTOzejTjjGRv4EBJDwGXAR+U9CvgiVxdRX5fnvMvBbYrzN8CPJbTW2qkryUizouIsRExdtiwYd25LWZm/V7DA0lEnBgRLRExgtSIflNEHAnMBCblbJOAq/LwTGCCpEGSdiQ1qs/J1V8rJe2Ze2tNLMxjZmYNUvejdhvgVGC6pGOAh4FDASJigaTppMf8rgKOi4jX8jzHAhcCGwHX55eZmTVQUwNJRMwGZufhJ4Fx7eSbCkytkd4K7NpzJTQzs874ynYzMyvFgcTMzEpxIDEzs1IcSMzMrBQHEjMzK8WBxMzMSnEgMTOzUhxIzMysFAcSMzMrxYHEzMxKcSAxM7NSHEjMzKwUBxIzMyvFgcTMzEpxIDEzs1IcSMzMrJSGBxJJ20n6k6T7JC2Q9O85fYikGyU9mN+3KMxzoqTFkhZJ2q+QPkbS/DztzPzIXTMza6BmnJGsAr4SEe8A9gSOkzQKOAGYFREjgVl5nDxtAjAa2B84W9KAvKxzgCmk57iPzNPNzKyBGh5IImJZRPwlD68E7gOGA+OBaTnbNOCgPDweuCwiXo6IJcBiYA9J2wCDI+L2iAjgosI8ZmbWIE1tI5E0AtgduBPYOiKWQQo2wFY523DgkcJsS3Pa8DxcnW5mZg3UtEAiaVPgt8AXI+LZjrLWSIsO0muta4qkVkmtbW1t615YMzNrV1MCiaT1SUHkkoi4Iic/kauryO/Lc/pSYLvC7C3AYzm9pUb6WiLivIgYGxFjhw0b1n0bYmZmTem1JeB84L6I+FFh0kxgUh6eBFxVSJ8gaZCkHUmN6nNy9ddKSXvmZU4szGNmZg0ysAnr3Bv4NDBf0ryc9g3gVGC6pGOAh4FDASJigaTpwEJSj6/jIuK1PN+xwIXARsD1+WVmZg3U8EASEX+mdvsGwLh25pkKTK2R3grs2n2lMzOzdeUr283MrBQHEjMzK8WBxMzMSnEgMTOzUhxIzMysFAcSMzMrxYHEzMxKcSAxM7NSHEjMzKwUBxIzMyvFgcTMzEpxIDEzs1IcSMzMrBQHEjMzK8WBxMzMSnEgMTOzUvp8IJG0v6RFkhZLOqHZ5TEz62/6dCCRNAD4KfARYBRwhKRRzS2VmVn/0qcDCbAHsDgi/hYRrwCXAeObXCYzs36lrweS4cAjhfGlOc3MzBpkYLMLUJJqpMVamaQpwJQ8+pykRT1aqv5lKLCi2YXoDXT6pGYXwdbkY7PipFo/letsh/Ym9PVAshTYrjDeAjxWnSkizgPOa1Sh+hNJrRExttnlMKvmY7Nx+nrV1l3ASEk7StoAmADMbHKZzMz6lT59RhIRqyQdD/wBGABcEBELmlwsM7N+pU8HEoCIuA64rtnl6MdcZWi9lY/NBlHEWm3TZmZmdevrbSRmZtZkDiTWJZI+K2liHp4sadvCtF/4DgPWm0jaXNLnCuPbSprRzDK9mbhqy0qTNBv4akS0NrssZrVIGgFcExG7Nrssb0Y+I+mHJI2QdL+kaZLukTRD0saSxkm6W9J8SRdIGpTznyppYc57ek47WdJXJR0CjAUukTRP0kaSZksaK+lYST8srHeypLPy8JGS5uR5zs33TbN+Kh+T90n6uaQFkm7Ix9LOkn4vaa6kWyW9PeffWdIdku6S9F1Jz+X0TSXNkvSXfBxXbpl0KrBzPt5Oy+u7N89zp6TRhbLMljRG0ib5e3BX/l749kvtiQi/+tkLGEG6A8DeefwC4Fuk283sktMuAr4IDAEWsfrsdfP8fjLpLARgNjC2sPzZpOAyjHQvtEr69cB7gXcAVwPr5/SzgYnN3i9+Nf2YXAXslsenA0cCs4CROe1fgZvy8DXAEXn4s8BzeXggMDgPDwUWk+6AMQK4t2p99+bhLwHfycPbAA/k4e8DR+bhzYEHgE2ava9648tnJP3XIxFxWx7+FTAOWBIRD+S0acA+wLPAS8AvJB0MvFDvCiKiDfibpD0lbQn8E3BbXtcY4C5J8/L4TuU3yfq4JRExLw/PJf3Yvwf4TT5OziX90APsBfwmD/+6sAwB35d0D/BH0r33tu5kvdOBQ/PwYYXlfhg4Ia97NrAhsP26bVL/0OevI7Euq6txLNJFn3uQfuwnAMcDH1yH9VxO+nLeD1wZESFJwLSIOHEdy2xvbi8Xhl8jBYCnI2K3dVjGp0hnwmMi4lVJD5ECQLsi4lFJT0r6Z+Bw4DN5koBPRoTvzdcJn5H0X9tL2isPH0H69zZC0tty2qeBmyVtCmwW6cLPLwK71VjWSuAt7aznCuCgvI7Lc9os4BBJWwFIGiKp3RvCWb/1LLBE0qEASt6Vp90BfDIPTyjMsxmwPAeRD7D6RoMdHaOQHkHxNdKxPj+n/QH4fP7jg6Tdy27Qm5UDSf91HzApVwEMAc4AjiJVI8wHXgd+RvryXZPz3UyqT652IfCzSmN7cUJEPAUsBHaIiDk5bSGpTeaGvNwbWV1lYVb0KeAYSf8DLGD184a+CHxZ0hzSsfNMTr8EGCupNc97P0BEPAncJuleSafVWM8MUkCaXkj7HrA+cE9umP9ed27Ym4m7//ZD7gppfZ2kjYEXc1XpBFLDu3tVNYnbSMysLxoD/CRXOz0NHN3c4vRvPiMxM7NS3EZiZmalOJCYmVkpDiRmZlaKA4lZA0naTdJHC+MHSjqhh9e5r6T39OQ6rH9zIDFrrN2ANwJJRMyMiFN7eJ37km41YtYj3GvLrE6SNiFdsNYCDCBdoLYY+BGwKbACmBwRy/Kt9e8EPkC64d8xeXwxsBHwKHBKHh4bEcdLuhB4EXg76Yrso4BJpPtK3RkRk3M5Pgx8BxgE/BU4KiKey7cDmQYcQLqQ7lDSfdLuIN1ypA34fETc2gO7x/oxn5GY1W9/4LGIeFe+mPP3wFnAIRExhnQX5amF/AMjYg/SVdgnRcQrwLeByyNit4i4nLVtQbqX2ZdId0g+AxgNvDNXiw0l3RXgQxHxL0Ar8OXC/Cty+jmkuzM/RLpDwRl5nQ4i1u18QaJZ/eYDp0v6Aek25k8BuwI35tsxDQCWFfJfkd8rd7Ktx9X5au35wBOV+z5JWpCX0QKMIt3uA2AD4PZ21nnwOmybWZc5kJjVKSIekDSG1MZxCukeYQsiYq92ZqnczfY16v+uVeZ5nTXvhvt6XsZrwI0RcUQ3rtOsFFdtmdVJ6bn0L0TEr4DTSQ9aGla5i7Kk9YtP2mtHZ3eh7cwdwN6VuzQrPdlylx5ep1mHHEjM6vdOYE5+0NE3Se0dhwA/yHennUfnvaP+BIzKd0o+fF0LkB8WNhm4NN85+Q5S43xHrgY+kdf5vnVdp1ln3GvLzMxK8RmJmZmV4kBiZmalOJCYmVkpDiRmZlaKA4mZmZXiQGJmZqU4kJiZWSkOJGZmVsr/B134BsSovBq5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (6,3))\n",
    "sns.countplot(x='sentiment' , data=df)\n",
    "plt.title(\"Positive Vs. Negative reviews count\", fontsize = 15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff1d4ae",
   "metadata": {},
   "source": [
    "## Upsampling the minority class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5963e94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>Nice, pleasant, and funny, but not earth-shatt...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23921</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15870</th>\n",
       "      <td>I pulled down a VHS box from my vast collectio...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>An original uncensored print of this amazing f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2641</th>\n",
       "      <td>After a summer full of retreads and disappoint...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19148</th>\n",
       "      <td>I am astounded that so many people find this f...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20303</th>\n",
       "      <td>Bo Derek will not go down in history as a grea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21057</th>\n",
       "      <td>\"Catchfire\" or \"Backtrack\" as it is sometimes ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22462</th>\n",
       "      <td>After sitting through this film, I have decide...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>This is s superbly crafted top-notch Washingto...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24948 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "8431   Nice, pleasant, and funny, but not earth-shatt...  positive\n",
       "23921  I always wrote this series off as being a comp...  negative\n",
       "15870  I pulled down a VHS box from my vast collectio...  positive\n",
       "16276  An original uncensored print of this amazing f...  positive\n",
       "2641   After a summer full of retreads and disappoint...  positive\n",
       "...                                                  ...       ...\n",
       "19148  I am astounded that so many people find this f...  negative\n",
       "20303  Bo Derek will not go down in history as a grea...  negative\n",
       "21057  \"Catchfire\" or \"Backtrack\" as it is sometimes ...  negative\n",
       "22462  After sitting through this film, I have decide...  negative\n",
       "23702  This is s superbly crafted top-notch Washingto...  positive\n",
       "\n",
       "[24948 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upsampling \n",
    "\n",
    "df_majority = df[df['sentiment'] == 'positive']\n",
    "df_minority = df[df['sentiment'] == 'negative']\n",
    "\n",
    "negative_upsample = resample(df_minority, replace = True, \n",
    "                        n_samples = df_majority.shape[0],\n",
    "                        random_state = 101)\n",
    "\n",
    "df_upsampled = pd.concat([negative_upsample, df_majority])  # concat two data frames i,e majority class data set and upsampled minority class data set\n",
    "df_upsampled = df_upsampled.sample(frac = 1)\n",
    "df_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade225a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12474, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled[df_upsampled['sentiment'] == 'negative'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ee538cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    10000\n",
       "positive    10000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Considering 10000 positive and 10000 negative data points\n",
    "negative_data_points_train = df_upsampled[df_upsampled['sentiment'] == 'negative'].iloc[:10000]\n",
    "positive_data_points_train = df_upsampled[df_upsampled['sentiment'] == 'positive'].iloc[:10000]\n",
    "\n",
    "## Considering the remaining data points for test\n",
    "negative_data_points_test = df_upsampled[df_upsampled['sentiment'] == 'negative'].iloc[10000:]\n",
    "positive_data_points_test = df_upsampled[df_upsampled['sentiment'] == 'positive'].iloc[10000:]\n",
    "\n",
    "## Concatenate the training positive and negative reviews\n",
    "X_train = pd.concat([negative_data_points_train['review'], positive_data_points_train['review']])\n",
    "## Concatenating the training positive and negative outputs\n",
    "y_train = pd.concat([negative_data_points_train['sentiment'], positive_data_points_train['sentiment']])\n",
    "\n",
    "## Concatenating the test positive and negative reviews\n",
    "X_test = pd.concat([negative_data_points_test['review'], positive_data_points_test['review']])\n",
    "## Concatenating the test positive and negative outputs\n",
    "y_test = pd.concat([negative_data_points_test['sentiment'], positive_data_points_test['sentiment']])\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "616b65c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2474\n",
       "positive    2474\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb6e21",
   "metadata": {},
   "source": [
    "## Pre-process the reviews\n",
    "\n",
    "The code in the cell below is performing text preprocessing on a given text. The preprocessing steps being applied include:\n",
    "\n",
    "1. Removing links\n",
    "2. Removing punctuations\n",
    "3. Removing stopwords\n",
    "4. Lowercasing the text\n",
    "5. Stemming the text.\n",
    "\n",
    "\n",
    "Stemming is the process of reducing words to their base or root form. This helps in grouping similar words together and treating them as the same word. The purpose of lowercasing the text is to ensure that words like 'Admire' and 'admire' are not considered as different words. All the punctuation marks and links are also removed to clean the text and make it ready for further processing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aee592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "def removeStopwords(text):\n",
    "    return \" \".join([word for word in re.split('\\W+', text) if word not in stopword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ea9193",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "def performStemming(text):\n",
    "     return\" \".join([ps.stem(word) for word in re.split('\\W+', text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fbd382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    '''\n",
    "    Parameter: review: a string containing a review.\n",
    "    Output: review_cleaned: a processed review. \n",
    "\n",
    "    '''\n",
    "    \n",
    "\n",
    "    review_cleaned = re.sub('http\\S+','',review)\n",
    "    review_cleaned = re.sub('www\\S+','',review)\n",
    "\n",
    "    review_cleaned = \"\".join([char for char in review_cleaned if char not in string.punctuation])\n",
    "    review_cleaned = removeStopwords(review_cleaned.lower())\n",
    "    \n",
    "    review_cleaned = performStemming(review_cleaned)\n",
    "    return review_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd099e",
   "metadata": {},
   "source": [
    "## find_occurrence function\n",
    "This function counts the number of times a specified word appears in all documents with a given label and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3d0e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_occurrence(frequency, word, label):\n",
    "    '''\n",
    "    Params:\n",
    "        frequency: a dictionary with the frequency of each pair (or tuple)\n",
    "        word: the word to look up\n",
    "        label: the label corresponding to the word\n",
    "    Return:\n",
    "        n: the number of times the word with its corresponding label appears.\n",
    "    '''\n",
    "    n = frequency[(word,label)]\n",
    "  \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a387d1",
   "metadata": {},
   "source": [
    "# Converting output to numerical format:\n",
    "\n",
    "We have outputs as 'positive' or 'negative'. In the cell below, we convert it to a numerical format. \n",
    "\n",
    "o is assigned to Positive labels and 1 to negative labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80311268",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_map = {'positive': 0, 'negative': 1}\n",
    "y_train = y_train.map(output_map)\n",
    "y_test = y_test.map(output_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac75912a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10000\n",
       "0    10000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b0c756a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily. But then one day a tragic happenstance occurred. After a White Sox game ended I realized that the remote was all the way on the other side of the room somehow. Now I could have just gotten up and walked across the room to get the remote, or even to the TV to turn the channel. But then why not just get up and walk across the country to watch TV in another state? \"Nuts to that\", I said. So I decided to just hang tight on the couch and take whatever Fate had in store for me. What Fate had in store was an episode of this show, an episode about which I remember very little except that I had once again made a very broad, general sweeping blanket judgment based on zero objective or experiential evidence with nothing whatsoever to back my opinions up with, and once again I was completely right! This show is a total crud-pie! Belushi has all the comedic delivery of a hairy lighthouse foghorn. The women are physically attractive but too Stepford-is to elicit any real feeling from the viewer. There is absolutely no reason to stop yourself from running down to the local TV station with a can of gasoline and a flamethrower and sending every copy of this mutt howling back to hell. <br /><br />Except.. <br /><br />Except for the wonderful comic sty lings of Larry Joe Campbell, America\\'s Greatest Comic Character Actor. This guy plays Belushi\\'s brother-in-law, Andy, and he is gold. How good is he really? Well, aside from being funny, his job is to make Belushi look good. That\\'s like trying to make butt warts look good. But Campbell pulls it off with style. Someone should invent a Nobel Prize in Comic Buffoonery so he can win it every year. Without Larry Joe this show would consist of a slightly vacant looking Courtney Thorne-Smith smacking Belushi over the head with a frying pan while he alternately beats his chest and plays with the straw on the floor of his cage. 5 stars for Larry Joe Campbell designated Comedic Bacon because he improves the flavor of everything he\\'s in!'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0090ce2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alway wrote seri complet stinkfest jim belushi involv heavili one day tragic happenst occur white sox game end realiz remot way side room somehow could gotten walk across room get remot even tv turn channel get walk across countri watch tv anoth state nut said decid hang tight couch take whatev fate store fate store episod show episod rememb littl except made broad gener sweep blanket judgment base zero object experienti evid noth whatsoev back opinion complet right show total crudpi belushi comed deliveri hairi lighthous foghorn women physic attract stepfordi elicit real feel viewer absolut reason stop run local tv station gasolin flamethrow send everi copi mutt howl back hell br br except br br except wonder comic sti ling larri joe campbel america greatest comic charact actor guy play belushi brotherinlaw andi gold good realli well asid funni job make belushi look good that like tri make butt wart look good campbel pull style someon invent nobel prize comic buffooneri win everi year without larri joe show would consist slightli vacant look courtney thornesmith smack belushi head fri pan altern beat chest play straw floor cage 5 star larri joe campbel design comed bacon improv flavor everyth he\n"
     ]
    }
   ],
   "source": [
    "custom_review = X_train.iloc[0]\n",
    "\n",
    "# print cleaned review\n",
    "print(clean_review(custom_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a04964c",
   "metadata": {},
   "source": [
    "## Implementing review counter function\n",
    "\n",
    "In this function, we count the occurrence of words and get the probabilities for the words based on the training data.\n",
    "\n",
    "We calculate the probabilites of the word occuring in both positive reviews and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a970639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_counter(output_occurrence, reviews, positive_or_negative):\n",
    "    '''\n",
    "    Params:\n",
    "        output_occurrence: a dictionary that will be used to map each pair to its frequency\n",
    "        reviews: a list of reviews\n",
    "        positive_or_negative: a list corresponding to the sentiment of each review (either 0 or 1)\n",
    "    Return:\n",
    "        output: a dictionary mapping each pair to its frequency\n",
    "    '''\n",
    "    \n",
    "    for label, review in zip(positive_or_negative, reviews):\n",
    "      split_review = clean_review(review).split()\n",
    "      for word in split_review:\n",
    "            if output_occurrence.get((word , label)) == None:\n",
    "                output_occurrence[(word , label)] = 1\n",
    "            else:\n",
    "                output_occurrence[(word , label)] += 1\n",
    "                \n",
    "   \n",
    "    return output_occurrence\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c2eba",
   "metadata": {},
   "source": [
    "## Testing function with sample reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4907eac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('got', 1): 1,\n",
       " ('bore', 1): 2,\n",
       " ('throught', 1): 1,\n",
       " ('moview', 1): 1,\n",
       " ('movi', 0): 2,\n",
       " ('fantast', 0): 1,\n",
       " ('watch', 1): 1,\n",
       " ('complet', 1): 1,\n",
       " ('wast', 1): 1,\n",
       " ('time', 1): 1,\n",
       " ('money', 1): 1,\n",
       " ('enjoy', 0): 1,\n",
       " ('fullest', 0): 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "result = {}\n",
    "reviews = ['got bored throught the moview', 'The movie was fantastic', 'Will not watch it again', 'Was bored, it was a complete waste of time and money', 'Enjoyed the movie to the fullest']\n",
    "ys = [1, 0, 1, 1, 0]\n",
    "review_counter(result,reviews, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "360afeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = review_counter({}, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c584747b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98917"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "026977ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('alway', 1): 920,\n",
       " ('wrote', 1): 282,\n",
       " ('seri', 1): 894,\n",
       " ('complet', 1): 1456,\n",
       " ('stinkfest', 1): 1,\n",
       " ('jim', 1): 150,\n",
       " ('belushi', 1): 17,\n",
       " ('involv', 1): 772,\n",
       " ('heavili', 1): 71,\n",
       " ('one', 1): 10446,\n",
       " ('day', 1): 1260,\n",
       " ('tragic', 1): 84,\n",
       " ('happenst', 1): 1,\n",
       " ('occur', 1): 147,\n",
       " ('white', 1): 460,\n",
       " ('sox', 1): 4,\n",
       " ('game', 1): 597,\n",
       " ('end', 1): 3608,\n",
       " ('realiz', 1): 463,\n",
       " ('remot', 1): 204,\n",
       " ('way', 1): 3185,\n",
       " ('side', 1): 482,\n",
       " ('room', 1): 379,\n",
       " ('somehow', 1): 347,\n",
       " ('could', 1): 3615,\n",
       " ('gotten', 1): 123,\n",
       " ('walk', 1): 636,\n",
       " ('across', 1): 398,\n",
       " ('get', 1): 6038,\n",
       " ('even', 1): 6272,\n",
       " ('tv', 1): 1031,\n",
       " ('turn', 1): 1526,\n",
       " ('channel', 1): 263,\n",
       " ('countri', 1): 275,\n",
       " ('watch', 1): 5836,\n",
       " ('anoth', 1): 1682,\n",
       " ('state', 1): 379,\n",
       " ('nut', 1): 50,\n",
       " ('said', 1): 996,\n",
       " ('decid', 1): 789,\n",
       " ('hang', 1): 194,\n",
       " ('tight', 1): 57,\n",
       " ('couch', 1): 29,\n",
       " ('take', 1): 2477,\n",
       " ('whatev', 1): 342,\n",
       " ('fate', 1): 95,\n",
       " ('store', 1): 245,\n",
       " ('episod', 1): 707,\n",
       " ('show', 1): 3278,\n",
       " ('rememb', 1): 651,\n",
       " ('littl', 1): 2327,\n",
       " ('except', 1): 799,\n",
       " ('made', 1): 3337,\n",
       " ('broad', 1): 34,\n",
       " ('gener', 1): 869,\n",
       " ('sweep', 1): 18,\n",
       " ('blanket', 1): 8,\n",
       " ('judgment', 1): 25,\n",
       " ('base', 1): 563,\n",
       " ('zero', 1): 184,\n",
       " ('object', 1): 139,\n",
       " ('experienti', 1): 1,\n",
       " ('evid', 1): 171,\n",
       " ('noth', 1): 2329,\n",
       " ('whatsoev', 1): 216,\n",
       " ('back', 1): 1828,\n",
       " ('opinion', 1): 336,\n",
       " ('right', 1): 1301,\n",
       " ('total', 1): 937,\n",
       " ('crudpi', 1): 1,\n",
       " ('comed', 1): 110,\n",
       " ('deliveri', 1): 57,\n",
       " ('hairi', 1): 31,\n",
       " ('lighthous', 1): 5,\n",
       " ('foghorn', 1): 1,\n",
       " ('women', 1): 785,\n",
       " ('physic', 1): 182,\n",
       " ('attract', 1): 323,\n",
       " ('stepfordi', 1): 1,\n",
       " ('elicit', 1): 27,\n",
       " ('real', 1): 1625,\n",
       " ('feel', 1): 1970,\n",
       " ('viewer', 1): 735,\n",
       " ('absolut', 1): 881,\n",
       " ('reason', 1): 1570,\n",
       " ('stop', 1): 669,\n",
       " ('run', 1): 1182,\n",
       " ('local', 1): 433,\n",
       " ('station', 1): 124,\n",
       " ('gasolin', 1): 5,\n",
       " ('flamethrow', 1): 9,\n",
       " ('send', 1): 173,\n",
       " ('everi', 1): 1531,\n",
       " ('copi', 1): 306,\n",
       " ('mutt', 1): 6,\n",
       " ('howl', 1): 22,\n",
       " ('hell', 1): 571,\n",
       " ('br', 1): 23415,\n",
       " ('wonder', 1): 1003,\n",
       " ('comic', 1): 395,\n",
       " ('sti', 1): 1,\n",
       " ('ling', 1): 3,\n",
       " ('larri', 1): 82,\n",
       " ('joe', 1): 213,\n",
       " ('campbel', 1): 48,\n",
       " ('america', 1): 249,\n",
       " ('greatest', 1): 148,\n",
       " ('charact', 1): 5552,\n",
       " ('actor', 1): 2724,\n",
       " ('guy', 1): 2173,\n",
       " ('play', 1): 2813,\n",
       " ('brotherinlaw', 1): 6,\n",
       " ('andi', 1): 76,\n",
       " ('gold', 1): 113,\n",
       " ('good', 1): 5829,\n",
       " ('realli', 1): 4963,\n",
       " ('well', 1): 3090,\n",
       " ('asid', 1): 200,\n",
       " ('funni', 1): 1684,\n",
       " ('job', 1): 641,\n",
       " ('make', 1): 6166,\n",
       " ('look', 1): 4604,\n",
       " ('that', 1): 1817,\n",
       " ('like', 1): 9592,\n",
       " ('tri', 1): 2995,\n",
       " ('butt', 1): 62,\n",
       " ('wart', 1): 5,\n",
       " ('pull', 1): 338,\n",
       " ('style', 1): 482,\n",
       " ('someon', 1): 1204,\n",
       " ('invent', 1): 116,\n",
       " ('nobel', 1): 4,\n",
       " ('prize', 1): 49,\n",
       " ('buffooneri', 1): 3,\n",
       " ('win', 1): 271,\n",
       " ('year', 1): 2112,\n",
       " ('without', 1): 1250,\n",
       " ('would', 1): 5639,\n",
       " ('consist', 1): 262,\n",
       " ('slightli', 1): 196,\n",
       " ('vacant', 1): 23,\n",
       " ('courtney', 1): 13,\n",
       " ('thornesmith', 1): 2,\n",
       " ('smack', 1): 28,\n",
       " ('head', 1): 859,\n",
       " ('fri', 1): 41,\n",
       " ('pan', 1): 46,\n",
       " ('altern', 1): 93,\n",
       " ('beat', 1): 202,\n",
       " ('chest', 1): 89,\n",
       " ('straw', 1): 22,\n",
       " ('floor', 1): 131,\n",
       " ('cage', 1): 117,\n",
       " ('5', 1): 461,\n",
       " ('star', 1): 1497,\n",
       " ('design', 1): 291,\n",
       " ('bacon', 1): 26,\n",
       " ('improv', 1): 171,\n",
       " ('flavor', 1): 11,\n",
       " ('everyth', 1): 969,\n",
       " ('he', 1): 1134,\n",
       " ('horribl', 1): 989,\n",
       " ('movi', 1): 22300,\n",
       " ('cannot', 1): 468,\n",
       " ('believ', 1): 1557,\n",
       " ('wast', 1): 1510,\n",
       " ('90', 1): 293,\n",
       " ('min', 1): 58,\n",
       " ('life', 1): 1659,\n",
       " ('remak', 1): 360,\n",
       " ('pleas', 1): 574,\n",
       " ('tell', 1): 1166,\n",
       " ('ving', 1): 6,\n",
       " ('rhame', 1): 5,\n",
       " ('mehki', 1): 4,\n",
       " ('pfifer', 1): 4,\n",
       " ('film', 1): 17225,\n",
       " ('great', 1): 2107,\n",
       " ('er', 1): 27,\n",
       " ('probabl', 1): 1226,\n",
       " ('didnt', 1): 2083,\n",
       " ('know', 1): 3082,\n",
       " ('terribl', 1): 1315,\n",
       " ('music', 1): 1194,\n",
       " ('background', 1): 237,\n",
       " ('must', 1): 1169,\n",
       " ('say', 1): 3263,\n",
       " ('fit', 1): 293,\n",
       " ('alllll', 1): 2,\n",
       " ('stori', 1): 4138,\n",
       " ('amaz', 1): 323,\n",
       " ('find', 1): 1965,\n",
       " ('director', 1): 2068,\n",
       " ('live', 1): 1292,\n",
       " ('creat', 1): 529,\n",
       " ('balanc', 1): 61,\n",
       " ('hope', 1): 964,\n",
       " ('futur', 1): 254,\n",
       " ('ever', 1): 2466,\n",
       " ('distroy', 1): 2,\n",
       " ('classic', 1): 525,\n",
       " ('first', 1): 3263,\n",
       " ('place', 1): 1075,\n",
       " ('advic', 1): 134,\n",
       " ('everyon', 1): 797,\n",
       " ('seen', 1): 2564,\n",
       " ('im', 1): 2239,\n",
       " ('couldnt', 1): 857,\n",
       " ('possibl', 1): 853,\n",
       " ('enjoy', 1): 1161,\n",
       " ('itbr', 1): 417,\n",
       " ('boooooo', 1): 2,\n",
       " ('10', 1): 816,\n",
       " ('unpleas', 1): 73,\n",
       " ('home', 1): 613,\n",
       " ('invas', 1): 36,\n",
       " ('genr', 1): 397,\n",
       " ('trace', 1): 50,\n",
       " ('we', 1): 39,\n",
       " ('craven', 1): 44,\n",
       " ('earli', 1): 461,\n",
       " ('sleazefest', 1): 3,\n",
       " ('last', 1): 1210,\n",
       " ('hous', 1): 793,\n",
       " ('left', 1): 927,\n",
       " ('nasti', 1): 167,\n",
       " ('offshoot', 1): 6,\n",
       " ('spit', 1): 56,\n",
       " ('grave', 1): 115,\n",
       " ('wrong', 1): 934,\n",
       " ('visitor', 1): 27,\n",
       " ('soon', 1): 395,\n",
       " ('follow', 1): 777,\n",
       " ('footstep', 1): 15,\n",
       " ('80', 1): 324,\n",
       " ('italian', 1): 228,\n",
       " ('offer', 1): 395,\n",
       " ('plot', 1): 3328,\n",
       " ('regurgit', 1): 11,\n",
       " ('twist', 1): 422,\n",
       " ('set', 1): 1475,\n",
       " ('continent', 1): 5,\n",
       " ('train', 1): 320,\n",
       " ('la', 1): 284,\n",
       " ('ragazza', 1): 17,\n",
       " ('del', 1): 42,\n",
       " ('vagon', 1): 17,\n",
       " ('letto', 1): 17,\n",
       " ('â', 1): 933,\n",
       " ('known', 1): 327,\n",
       " ('englishspeak', 1): 4,\n",
       " ('terror', 1): 109,\n",
       " ('express', 1): 233,\n",
       " ('start', 1): 1763,\n",
       " ('surprisingli', 1): 122,\n",
       " ('twenti', 1): 122,\n",
       " ('minut', 1): 2016,\n",
       " ('wors', 1): 965,\n",
       " ('sex', 1): 808,\n",
       " ('scene', 1): 4547,\n",
       " ('gain', 1): 88,\n",
       " ('preced', 1): 29,\n",
       " ('seriou', 1): 412,\n",
       " ('action', 1): 1294,\n",
       " ('suspensebr', 1): 6,\n",
       " ('david', 1): 268,\n",
       " ('phil', 1): 45,\n",
       " ('erni', 1): 12,\n",
       " ('three', 1): 843,\n",
       " ('rich', 1): 215,\n",
       " ('youth', 1): 104,\n",
       " ('wallow', 1): 16,\n",
       " ('terroris', 1): 25,\n",
       " ('humili', 1): 57,\n",
       " ('other', 1): 530,\n",
       " ('board', 1): 130,\n",
       " ('transcontinent', 1): 3,\n",
       " ('itali', 1): 68,\n",
       " ('full', 1): 597,\n",
       " ('passeng', 1): 53,\n",
       " ('among', 1): 234,\n",
       " ('prostitut', 1): 82,\n",
       " ('juliett', 1): 14,\n",
       " ('silvia', 1): 6,\n",
       " ('dionisio', 1): 5,\n",
       " ('ride', 1): 194,\n",
       " ('frequent', 1): 94,\n",
       " ('struck', 1): 36,\n",
       " ('deal', 1): 487,\n",
       " ('porter', 1): 17,\n",
       " ('act', 1): 4120,\n",
       " ('kind', 1): 1346,\n",
       " ('pimp', 1): 31,\n",
       " ('persuad', 1): 26,\n",
       " ('male', 1): 340,\n",
       " ('part', 1): 1980,\n",
       " ('cash', 1): 122,\n",
       " ('night', 1): 870,\n",
       " ('passion', 1): 114,\n",
       " ('sleep', 1): 216,\n",
       " ('compart', 1): 12,\n",
       " ('cretin', 1): 17,\n",
       " ('quickli', 1): 235,\n",
       " ('upset', 1): 84,\n",
       " ('aggress', 1): 38,\n",
       " ('drunken', 1): 45,\n",
       " ('behaviour', 1): 24,\n",
       " ('matter', 1): 533,\n",
       " ('seiz', 1): 12,\n",
       " ('control', 1): 222,\n",
       " ('entir', 1): 881,\n",
       " ('car', 1): 728,\n",
       " ('barricad', 1): 24,\n",
       " ('rest', 1): 804,\n",
       " ('pretti', 1): 1683,\n",
       " ('revel', 1): 93,\n",
       " ('temporari', 1): 9,\n",
       " ('controlâ', 1): 3,\n",
       " ('young', 1): 996,\n",
       " ('wife', 1): 637,\n",
       " ('zora', 1): 3,\n",
       " ('kerova', 1): 6,\n",
       " ('rape', 1): 250,\n",
       " ('two', 1): 2505,\n",
       " ('cramp', 1): 7,\n",
       " ('subject', 1): 352,\n",
       " ('prolong', 1): 16,\n",
       " ('sexual', 1): 328,\n",
       " ('assault', 1): 60,\n",
       " ('later', 1): 744,\n",
       " ('odiou', 1): 11,\n",
       " ('trio', 1): 44,\n",
       " ('forc', 1): 632,\n",
       " ('role', 1): 1299,\n",
       " ('dice', 1): 16,\n",
       " ('order', 1): 466,\n",
       " ('16', 1): 31,\n",
       " ('old', 1): 1469,\n",
       " ('virgin', 1): 67,\n",
       " ('travel', 1): 203,\n",
       " ('parent', 1): 293,\n",
       " ('concept', 1): 294,\n",
       " ('doubli', 1): 13,\n",
       " ('tasteless', 1): 60,\n",
       " ('fact', 1): 1555,\n",
       " ('father', 1): 585,\n",
       " ('men', 1): 687,\n",
       " ('seem', 1): 3269,\n",
       " ('prepar', 1): 135,\n",
       " ('fight', 1): 792,\n",
       " ('convict', 1): 81,\n",
       " ('escort', 1): 18,\n",
       " ('germani', 1): 62,\n",
       " ('man', 1): 1850,\n",
       " ('arm', 1): 212,\n",
       " ('thug', 1): 68,\n",
       " ('decent', 1): 720,\n",
       " ('variou', 1): 231,\n",
       " ('intrigu', 1): 177,\n",
       " ('introduc', 1): 212,\n",
       " ('hoodlum', 1): 15,\n",
       " ('shown', 1): 355,\n",
       " ('genuin', 1): 132,\n",
       " ('unsettl', 1): 28,\n",
       " ('influenc', 1): 98,\n",
       " ('though', 1): 1605,\n",
       " ('clearli', 1): 363,\n",
       " ('stuff', 1): 533,\n",
       " ('exploit', 1): 238,\n",
       " ('open', 1): 830,\n",
       " ('built', 1): 66,\n",
       " ('care', 1): 871,\n",
       " ('rise', 1): 154,\n",
       " ('usual', 1): 713,\n",
       " ('gutterlevel', 1): 3,\n",
       " ('thing', 1): 3657,\n",
       " ('fall', 1): 786,\n",
       " ('apart', 1): 362,\n",
       " ('horrid', 1): 97,\n",
       " ('sexsandwich', 1): 3,\n",
       " ('toilet', 1): 75,\n",
       " ('gloatingli', 1): 4,\n",
       " ('effect', 1): 1547,\n",
       " ('sympathi', 1): 89,\n",
       " ('victim', 1): 343,\n",
       " ('hatr', 1): 42,\n",
       " ('toward', 1): 351,\n",
       " ('perpetratorsâ', 1): 3,\n",
       " ('instead', 1): 1115,\n",
       " ('ask', 1): 686,\n",
       " ('sensation', 1): 3,\n",
       " ('worst', 1): 1872,\n",
       " ('sequenc', 1): 661,\n",
       " ('much', 1): 3858,\n",
       " ('linger', 1): 26,\n",
       " ('camera', 1): 906,\n",
       " ('work', 1): 2439,\n",
       " ('oral', 1): 18,\n",
       " ('femal', 1): 501,\n",
       " ('genitalia', 1): 13,\n",
       " ('featur', 1): 687,\n",
       " ('girl', 1): 1651,\n",
       " ('teeter', 1): 6,\n",
       " ('brink', 1): 44,\n",
       " ('hard', 1): 1042,\n",
       " ('core', 1): 98,\n",
       " ('particularli', 1): 403,\n",
       " ('easi', 1): 230,\n",
       " ('forget', 1): 313,\n",
       " ('intend', 1): 199,\n",
       " ('thriller', 1): 336,\n",
       " ('final', 1): 1134,\n",
       " ('hour', 1): 965,\n",
       " ('dedic', 1): 49,\n",
       " ('pornographi', 1): 34,\n",
       " ('rather', 1): 1121,\n",
       " ('suspens', 1): 370,\n",
       " ('lover', 1): 215,\n",
       " ('sleaz', 1): 72,\n",
       " ('might', 1): 1304,\n",
       " ('want', 1): 2872,\n",
       " ('elsewher', 1): 63,\n",
       " ('oh', 1): 757,\n",
       " ('beginbr', 1): 3,\n",
       " ('drop', 1): 205,\n",
       " ('gun', 1): 370,\n",
       " ('hand', 1): 745,\n",
       " ('combat', 1): 43,\n",
       " ('w', 1): 25,\n",
       " ('zombi', 1): 641,\n",
       " ('hold', 1): 363,\n",
       " ('bitten', 1): 37,\n",
       " ('soldier', 1): 235,\n",
       " ('debat', 1): 54,\n",
       " ('shoot', 1): 480,\n",
       " ('b4', 1): 2,\n",
       " ('bite', 1): 71,\n",
       " ('person', 1): 1238,\n",
       " ('fallen', 1): 61,\n",
       " ('continu', 1): 476,\n",
       " ('see', 1): 5079,\n",
       " ('doesnt', 1): 2007,\n",
       " ('idea', 1): 1317,\n",
       " ('kid', 1): 1193,\n",
       " ('slump', 1): 9,\n",
       " ('desk', 1): 15,\n",
       " ('blood', 1): 492,\n",
       " ('come', 1): 2518,\n",
       " ('mouth', 1): 188,\n",
       " ('still', 1): 1791,\n",
       " ('alright', 1): 126,\n",
       " ('along', 1): 690,\n",
       " ('footbal', 1): 105,\n",
       " ('field', 1): 121,\n",
       " ('sudden', 1): 94,\n",
       " ('notic', 1): 313,\n",
       " ('team', 1): 317,\n",
       " ('middl', 1): 339,\n",
       " ('pointbr', 1): 23,\n",
       " ('go', 1): 3840,\n",
       " ('pointchildish', 1): 2,\n",
       " ('write', 1): 932,\n",
       " ('dialog', 1): 487,\n",
       " ('bad', 1): 5701,\n",
       " ('direct', 1): 1489,\n",
       " ('special', 1): 932,\n",
       " ('truli', 1): 635,\n",
       " ('sad', 1): 421,\n",
       " ('undevelop', 1): 27,\n",
       " ('storylin', 1): 364,\n",
       " ('infest', 1): 11,\n",
       " ('campu', 1): 24,\n",
       " ('viral', 1): 5,\n",
       " ('host', 1): 113,\n",
       " ('lose', 1): 294,\n",
       " ('ittwic', 1): 2,\n",
       " ('plu', 1): 274,\n",
       " ('includ', 1): 740,\n",
       " ('clip', 1): 101,\n",
       " ('actual', 1): 2325,\n",
       " ('scenesbr', 1): 37,\n",
       " ('id', 1): 608,\n",
       " ('dont', 1): 4233,\n",
       " ('money', 1): 1206,\n",
       " ('time', 1): 5777,\n",
       " ('saw', 1): 1139,\n",
       " ('cabl', 1): 117,\n",
       " ('2', 1): 1099,\n",
       " ('may', 1): 1121,\n",
       " ('ill', 1): 516,\n",
       " ('100', 1): 170,\n",
       " ('think', 1): 3525,\n",
       " ('group', 1): 495,\n",
       " ('firstgrad', 1): 2,\n",
       " ('better', 1): 2573,\n",
       " ('line', 1): 1417,\n",
       " ('class', 1): 310,\n",
       " ('project', 1): 365,\n",
       " ('dumber', 1): 38,\n",
       " ('god', 1): 595,\n",
       " ('merci', 1): 58,\n",
       " ('soul', 1): 195,\n",
       " ('paid', 1): 178,\n",
       " ('produc', 1): 840,\n",
       " ('filmbr', 1): 348,\n",
       " ('urg', 1): 42,\n",
       " ('vomitbr', 1): 4,\n",
       " ('clue', 1): 148,\n",
       " ('photographi', 1): 157,\n",
       " ('anythingbr', 1): 22,\n",
       " ('cant', 1): 1831,\n",
       " ('fx', 1): 75,\n",
       " ('crap', 1): 647,\n",
       " ('occas', 1): 66,\n",
       " ('starz', 1): 7,\n",
       " ('main', 1): 1004,\n",
       " ('3', 1): 702,\n",
       " ('wow', 1): 169,\n",
       " ('thought', 1): 1459,\n",
       " ('steven', 1): 166,\n",
       " ('segal', 1): 35,\n",
       " ('prove', 1): 367,\n",
       " ('carri', 1): 392,\n",
       " ('also', 1): 2930,\n",
       " ('lot', 1): 1851,\n",
       " ('mistak', 1): 300,\n",
       " ('proper', 1): 115,\n",
       " ('archiolog', 1): 3,\n",
       " ('dig', 1): 81,\n",
       " ('done', 1): 1144,\n",
       " ('instanc', 1): 156,\n",
       " ('handl', 1): 194,\n",
       " ('artifact', 1): 12,\n",
       " ('until', 1): 3,\n",
       " ('catolog', 1): 3,\n",
       " ('account', 1): 132,\n",
       " ('biggest', 1): 252,\n",
       " ('crime', 1): 288,\n",
       " ('cast', 1): 1643,\n",
       " ('archiologist', 1): 3,\n",
       " ('weak', 1): 394,\n",
       " ('actress', 1): 569,\n",
       " ('felt', 1): 649,\n",
       " ('less', 1): 720,\n",
       " ('realist', 1): 188,\n",
       " ('alreadi', 1): 605,\n",
       " ('whole', 1): 1450,\n",
       " ('knight', 1): 42,\n",
       " ('templar', 1): 15,\n",
       " ('underground', 1): 86,\n",
       " ('stupid', 1): 1302,\n",
       " ('disappear', 1): 169,\n",
       " ('almost', 1): 1238,\n",
       " ('depress', 1): 211,\n",
       " ('wernt', 1): 3,\n",
       " ('explain', 1): 493,\n",
       " ('enough', 1): 1541,\n",
       " ('harder', 1): 59,\n",
       " ('relat', 1): 237,\n",
       " ('love', 1): 2216,\n",
       " ('kevin', 1): 134,\n",
       " ('spacey', 1): 73,\n",
       " ('knew', 1): 312,\n",
       " ('big', 1): 1330,\n",
       " ('brain', 1): 269,\n",
       " ('brad', 1): 81,\n",
       " ('pulp', 1): 32,\n",
       " ('fiction', 1): 212,\n",
       " ('prick', 1): 9,\n",
       " ('happen', 1): 1586,\n",
       " ('especi', 1): 736,\n",
       " ('endingthat', 1): 1,\n",
       " ('hate', 1): 620,\n",
       " ('wreck', 1): 102,\n",
       " ('recommend', 1): 679,\n",
       " ('opportun', 1): 162,\n",
       " ('best', 1): 1666,\n",
       " ('romant', 1): 201,\n",
       " ('tragedi', 1): 84,\n",
       " ('mafia', 1): 33,\n",
       " ('actorsth', 1): 3,\n",
       " ('budgetand', 1): 3,\n",
       " ('john', 1): 711,\n",
       " ('huston', 1): 44,\n",
       " ('preoccupi', 1): 4,\n",
       " ('mellow', 1): 6,\n",
       " ('miss', 1): 876,\n",
       " ('classicstrenu', 1): 3,\n",
       " ('black', 1): 822,\n",
       " ('humor', 1): 541,\n",
       " ('often', 1): 513,\n",
       " ('dilut', 1): 8,\n",
       " ('muchand', 1): 5,\n",
       " ('uncar', 1): 11,\n",
       " ('detail', 1): 302,\n",
       " ('sound', 1): 1089,\n",
       " ('actionmayb', 1): 3,\n",
       " ('age', 1): 464,\n",
       " ('pass', 1): 379,\n",
       " ('away', 1): 1059,\n",
       " ('high', 1): 714,\n",
       " ('expect', 1): 1248,\n",
       " ('excit', 1): 350,\n",
       " ('rent', 1): 675,\n",
       " ('disappoint', 1): 947,\n",
       " ('poorli', 1): 544,\n",
       " ('written', 1): 522,\n",
       " ('sort', 1): 757,\n",
       " ('fell', 1): 189,\n",
       " ('wasnt', 1): 1099,\n",
       " ('anyth', 1): 1492,\n",
       " ('mayb', 1): 1114,\n",
       " ('devil', 1): 149,\n",
       " ('repres', 1): 130,\n",
       " ('gasp', 1): 34,\n",
       " ('occult', 1): 17,\n",
       " ('obsess', 1): 156,\n",
       " ('horror', 1): 1583,\n",
       " ('70', 1): 227,\n",
       " ('shortli', 1): 50,\n",
       " ('halloween', 1): 69,\n",
       " ('came', 1): 638,\n",
       " ('tore', 1): 5,\n",
       " ('rule', 1): 155,\n",
       " ('book', 1): 1211,\n",
       " ('fire', 1): 437,\n",
       " ('kick', 1): 234,\n",
       " ('scream', 1): 346,\n",
       " ('plate', 1): 19,\n",
       " ('glass', 1): 68,\n",
       " ('windowbr', 1): 12,\n",
       " ('cut', 1): 674,\n",
       " ('long', 1): 1270,\n",
       " ('short', 1): 732,\n",
       " ('coupl', 1): 839,\n",
       " ('enterpris', 1): 28,\n",
       " ('greek', 1): 61,\n",
       " ('maker', 1): 220,\n",
       " ('fanci', 1): 69,\n",
       " ('chanc', 1): 355,\n",
       " ('nail', 1): 57,\n",
       " ('togeth', 1): 759,\n",
       " ('new', 1): 1333,\n",
       " ('franchis', 1): 82,\n",
       " ('unlik', 1): 324,\n",
       " ('doubl', 1): 128,\n",
       " ('womanis', 1): 1,\n",
       " ('wise', 1): 99,\n",
       " ('talk', 1): 876,\n",
       " ('american', 1): 857,\n",
       " ('investig', 1): 189,\n",
       " ('milo', 1): 38,\n",
       " ('stuffi', 1): 6,\n",
       " ('heart', 1): 331,\n",
       " ('priest', 1): 120,\n",
       " ('roch', 1): 6,\n",
       " ('exil', 1): 8,\n",
       " ('nobleman', 1): 5,\n",
       " ('mix', 1): 228,\n",
       " ('satan', 1): 97,\n",
       " ('jiggeri', 1): 1,\n",
       " ('pokeri', 1): 1,\n",
       " ('tourist', 1): 36,\n",
       " ('sacrific', 1): 57,\n",
       " ('extrem', 1): 632,\n",
       " ('unfrighten', 1): 1,\n",
       " ('effigi', 1): 2,\n",
       " ('minotaur', 1): 11,\n",
       " ('someth', 1): 2271,\n",
       " ('thatbr', 1): 120,\n",
       " ('realiti', 1): 284,\n",
       " ('howev', 1): 1337,\n",
       " ('dull', 1): 544,\n",
       " ('frustrat', 1): 124,\n",
       " ('load', 1): 129,\n",
       " ('strongli', 1): 51,\n",
       " ('suspect', 1): 207,\n",
       " ('fledgl', 1): 4,\n",
       " ('blew', 1): 32,\n",
       " ('budget', 1): 871,\n",
       " ('donald', 1): 59,\n",
       " ('plesanc', 1): 1,\n",
       " ('peter', 1): 269,\n",
       " ('cush', 1): 34,\n",
       " ('brian', 1): 69,\n",
       " ('eno', 1): 4,\n",
       " ('soundtrack', 1): 248,\n",
       " ('onboard', 1): 12,\n",
       " ('sway', 1): 17,\n",
       " ('audienc', 1): 1072,\n",
       " ('english', 1): 308,\n",
       " ('speak', 1): 454,\n",
       " ('worldbr', 1): 46,\n",
       " ('isnt', 1): 1530,\n",
       " ('beauti', 1): 749,\n",
       " ('assur', 1): 55,\n",
       " ('camerawork', 1): 56,\n",
       " ('fantast', 1): 110,\n",
       " ('locat', 1): 333,\n",
       " ('score', 1): 350,\n",
       " ('basic', 1): 702,\n",
       " ('chord', 1): 9,\n",
       " ('drone', 1): 46,\n",
       " ('crank', 1): 14,\n",
       " ('afternoon', 1): 51,\n",
       " ('suitabl', 1): 58,\n",
       " ('atmospher', 1): 243,\n",
       " ('laden', 1): 7,\n",
       " ('crack', 1): 90,\n",
       " ('crumpet', 1): 1,\n",
       " ('austrailian', 1): 1,\n",
       " ('fawlti', 1): 12,\n",
       " ('tower', 1): 53,\n",
       " ('uber', 1): 5,\n",
       " ('hotti', 1): 11,\n",
       " ('jane', 1): 199,\n",
       " ('lyle', 1): 9,\n",
       " ('island', 1): 376,\n",
       " ('death', 1): 760,\n",
       " ('infami', 1): 3,\n",
       " ('posit', 1): 387,\n",
       " ('sleepwalk', 1): 30,\n",
       " ('corn', 1): 37,\n",
       " ('cob', 1): 1,\n",
       " ('bum', 1): 36,\n",
       " ('pleasanc', 1): 14,\n",
       " ('fuss', 1): 18,\n",
       " ('never', 1): 2759,\n",
       " ('quit', 1): 1312,\n",
       " ('appallingli', 1): 17,\n",
       " ('flimsi', 1): 36,\n",
       " ('unlikeablebr', 1): 1,\n",
       " ('okay', 1): 381,\n",
       " ('simpli', 1): 837,\n",
       " ('refus', 1): 111,\n",
       " ('anywher', 1): 127,\n",
       " ('insinu', 1): 14,\n",
       " ('villag', 1): 82,\n",
       " ('possess', 1): 144,\n",
       " ('fair', 1): 223,\n",
       " ('shuffl', 1): 31,\n",
       " ('glassi', 1): 1,\n",
       " ('eye', 1): 655,\n",
       " ('perhap', 1): 681,\n",
       " ('tire', 1): 279,\n",
       " ('sure', 1): 1259,\n",
       " ('interrupt', 1): 30,\n",
       " ('baron', 1): 27,\n",
       " ('parti', 1): 260,\n",
       " ('laughabl', 1): 331,\n",
       " ('eas', 1): 27,\n",
       " ('meet', 1): 508,\n",
       " ('statu', 1): 72,\n",
       " ('silent', 1): 181,\n",
       " ('hey', 1): 196,\n",
       " ('presto', 1): 1,\n",
       " ('defeatedbr', 1): 2,\n",
       " ('yeah', 1): 234,\n",
       " ('rightbr', 1): 37,\n",
       " ('inan', 1): 88,\n",
       " ('optim', 1): 13,\n",
       " ('hammer', 1): 65,\n",
       " ('mere', 1): 206,\n",
       " ('second', 1): 866,\n",
       " ('ridicul', 1): 716,\n",
       " ('rush', 1): 122,\n",
       " ('call', 1): 1245,\n",
       " ('upon', 1): 349,\n",
       " ('help', 1): 969,\n",
       " ('defeat', 1): 75,\n",
       " ('antichrist', 1): 16,\n",
       " ('youll', 1): 518,\n",
       " ('put', 1): 1356,\n",
       " ('friend', 1): 1148,\n",
       " ('10ish', 1): 3,\n",
       " ('buff', 1): 74,\n",
       " ('shockingli', 1): 30,\n",
       " ('whoever', 1): 120,\n",
       " ('hollywood', 1): 698,\n",
       " ('career', 1): 397,\n",
       " ('although', 1): 755,\n",
       " ('lead', 1): 1026,\n",
       " ('accord', 1): 103,\n",
       " ('imdb', 1): 344,\n",
       " ('albeit', 1): 44,\n",
       " ('havent', 1): 288,\n",
       " ('muchbr', 1): 48,\n",
       " ('anyway', 1): 522,\n",
       " ('od', 1): 5,\n",
       " ('jack', 1): 287,\n",
       " ('frost', 1): 30,\n",
       " ('return', 1): 410,\n",
       " ('armi', 1): 185,\n",
       " ('styrofoam', 1): 5,\n",
       " ('ball', 1): 142,\n",
       " ('foil', 1): 26,\n",
       " ('shot', 1): 1263,\n",
       " ('supersoak', 1): 1,\n",
       " ('margarita', 1): 5,\n",
       " ('how', 1): 11,\n",
       " ('hing', 1): 12,\n",
       " ('premis', 1): 318,\n",
       " ('bare', 1): 388,\n",
       " ('rais', 1): 189,\n",
       " ('eyebrow', 1): 24,\n",
       " ('kill', 1): 1814,\n",
       " ('bbq', 1): 1,\n",
       " ('tong', 1): 15,\n",
       " ('impal', 1): 37,\n",
       " ('carrot', 1): 22,\n",
       " ('skate', 1): 22,\n",
       " ('thin', 1): 133,\n",
       " ('ice', 1): 102,\n",
       " ('baboomtishbr', 1): 1,\n",
       " ('admittedli', 1): 76,\n",
       " ('onelin', 1): 65,\n",
       " ('remark', 1): 121,\n",
       " ('murder', 1): 715,\n",
       " ('coconut', 1): 1,\n",
       " ('sharkbr', 1): 2,\n",
       " ('excus', 1): 306,\n",
       " ('willing', 1): 4,\n",
       " ('utter', 1): 179,\n",
       " ('tripebr', 1): 11,\n",
       " ('fan', 1): 1234,\n",
       " ('accept', 1): 279,\n",
       " ('phallic', 1): 3,\n",
       " ('creep', 1): 45,\n",
       " ('beach', 1): 142,\n",
       " ('corni', 1): 118,\n",
       " ('voiceov', 1): 60,\n",
       " ('commentari', 1): 112,\n",
       " ('emperor', 1): 69,\n",
       " ('groov', 1): 26,\n",
       " ('disney', 1): 235,\n",
       " ('clean', 1): 92,\n",
       " ('fresh', 1): 110,\n",
       " ('joke', 1): 785,\n",
       " ('polit', 1): 312,\n",
       " ('darn', 1): 40,\n",
       " ('moviebr', 1): 419,\n",
       " ('kronk', 1): 33,\n",
       " ('3yearold', 1): 3,\n",
       " ('asleep', 1): 98,\n",
       " ('conflict', 1): 141,\n",
       " ('wacki', 1): 32,\n",
       " ('adventur', 1): 160,\n",
       " ('lack', 1): 989,\n",
       " ('anim', 1): 617,\n",
       " ('threw', 1): 69,\n",
       " ('writer', 1): 671,\n",
       " ('went', 1): 668,\n",
       " ('alongbr', 1): 17,\n",
       " ('kept', 1): 337,\n",
       " ('wait', 1): 584,\n",
       " ('fun', 1): 792,\n",
       " ('check', 1): 360,\n",
       " ('6', 1): 175,\n",
       " ('vote', 1): 183,\n",
       " ('72', 1): 7,\n",
       " ('serious', 1): 501,\n",
       " ('let', 1): 1300,\n",
       " ('break', 1): 408,\n",
       " ('handheld', 1): 30,\n",
       " ('digit', 1): 54,\n",
       " ('own', 1): 72,\n",
       " ('freshman', 1): 13,\n",
       " ('commun', 1): 183,\n",
       " ('colleg', 1): 213,\n",
       " ('next', 1): 701,\n",
       " ('met', 1): 107,\n",
       " ('pub', 1): 21,\n",
       " ('third', 1): 233,\n",
       " ('list', 1): 299,\n",
       " ('edit', 1): 598,\n",
       " ('cram', 1): 22,\n",
       " ('mani', 1): 2296,\n",
       " ('song', 1): 579,\n",
       " ('30', 1): 297,\n",
       " ('interv', 1): 10,\n",
       " ('pc', 1): 28,\n",
       " ('use', 1): 2049,\n",
       " ('window', 1): 141,\n",
       " ('pretenti', 1): 201,\n",
       " ('undeni', 1): 31,\n",
       " ('script', 1): 1779,\n",
       " ('suit', 1): 203,\n",
       " ('wouldnt', 1): 539,\n",
       " ('anyon', 1): 1101,\n",
       " ('sentenc', 1): 83,\n",
       " ('etern', 1): 57,\n",
       " ('despit', 1): 517,\n",
       " ('2001', 1): 58,\n",
       " ('arthous', 1): 28,\n",
       " ('consid', 1): 573,\n",
       " ('outofd', 1): 2,\n",
       " ('ago', 1): 393,\n",
       " ('cheesi', 1): 339,\n",
       " ('pain', 1): 523,\n",
       " ('captiv', 1): 65,\n",
       " ('taxi', 1): 23,\n",
       " ('driver', 1): 86,\n",
       " ('bring', 1): 575,\n",
       " ('bridg', 1): 64,\n",
       " ('detect', 1): 154,\n",
       " ('who', 1): 252,\n",
       " ('sister', 1): 233,\n",
       " ('suicid', 1): 162,\n",
       " ('plain', 1): 349,\n",
       " ('perform', 1): 1493,\n",
       " ('selma', 1): 4,\n",
       " ('blair', 1): 84,\n",
       " ('marri', 1): 261,\n",
       " ('boyfriend', 1): 187,\n",
       " ('bother', 1): 397,\n",
       " ('sit', 1): 636,\n",
       " ('rare', 1): 188,\n",
       " ('random', 1): 239,\n",
       " ('whatisthi', 1): 2,\n",
       " ('porn', 1): 194,\n",
       " ('legend', 1): 113,\n",
       " ('gregori', 1): 11,\n",
       " ('dark', 1): 635,\n",
       " ('flick', 1): 787,\n",
       " ('glen', 1): 19,\n",
       " ('jacob', 1): 12,\n",
       " ('kane', 1): 58,\n",
       " ('wwfwwe', 1): 2,\n",
       " ('nowaday', 1): 32,\n",
       " ('cinemat', 1): 183,\n",
       " ('debut', 1): 74,\n",
       " ('goodknight', 1): 2,\n",
       " ('blind', 1): 104,\n",
       " ('serial', 1): 133,\n",
       " ('killer', 1): 701,\n",
       " ('fort', 1): 28,\n",
       " ('peopl', 1): 3659,\n",
       " ('troubl', 1): 299,\n",
       " ('histor', 1): 223,\n",
       " ('hotel', 1): 121,\n",
       " ('resid', 1): 78,\n",
       " ('subsequ', 1): 48,\n",
       " ('of', 1): 14,\n",
       " ('hemmingway', 1): 1,\n",
       " ('dopey', 1): 20,\n",
       " ('bmovi', 1): 137,\n",
       " ('tediou', 1): 178,\n",
       " ('glad', 1): 146,\n",
       " ('low', 1): 803,\n",
       " ('werent', 1): 211,\n",
       " ('king', 1): 321,\n",
       " ('suffer', 1): 328,\n",
       " ('nuditi', 1): 290,\n",
       " ('shamebr', 1): 3,\n",
       " ('grade', 1): 210,\n",
       " ('candi', 1): 113,\n",
       " ('samantha', 1): 27,\n",
       " ('nobl', 1): 25,\n",
       " ('ass', 1): 130,\n",
       " ('briefli', 1): 84,\n",
       " ('standard', 1): 335,\n",
       " ('schmaltz', 1): 2,\n",
       " ('mile', 1): 148,\n",
       " ('predict', 1): 576,\n",
       " ('confess', 1): 90,\n",
       " ('tough', 1): 143,\n",
       " ('sweet', 1): 101,\n",
       " ('give', 1): 2214,\n",
       " ('nice', 1): 753,\n",
       " ('backdrop', 1): 45,\n",
       " ('irritatingli', 1): 12,\n",
       " ('unorigin', 1): 93,\n",
       " ('spend', 1): 443,\n",
       " ('lifebr', 1): 40,\n",
       " ('chick', 1): 200,\n",
       " ('press', 1): 82,\n",
       " ('scari', 1): 417,\n",
       " ('14', 1): 41,\n",
       " ('epic', 1): 114,\n",
       " ('date', 1): 283,\n",
       " ('spartan', 1): 15,\n",
       " ('teen', 1): 211,\n",
       " ('gay', 1): 351,\n",
       " ('superhero', 1): 56,\n",
       " ('eleventh', 1): 3,\n",
       " ('singl', 1): 375,\n",
       " ('handili', 1): 2,\n",
       " ('ruin', 1): 299,\n",
       " ('parodi', 1): 149,\n",
       " ('admit', 1): 309,\n",
       " ('soft', 1): 112,\n",
       " ('spot', 1): 189,\n",
       " ('airplan', 1): 67,\n",
       " ('nake', 1): 228,\n",
       " ('youv', 1): 321,\n",
       " ('milk', 1): 43,\n",
       " ('gag', 1): 192,\n",
       " ('temp', 1): 9,\n",
       " ('disast', 1): 192,\n",
       " ('incred', 1): 397,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df2b99",
   "metadata": {},
   "source": [
    "## Training the Naive Bayes Model\n",
    "\n",
    "This code is implementing the training phase of the Naive Bayes algorithm. \n",
    "\n",
    "It focuses on calculating the log likelihood and log prior values, which are crucial for the testing phase in subsequent cells. \n",
    "\n",
    "The function returns the logprior and loglikelihood values generated by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bef7c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    '''\n",
    "    Input:\n",
    "        freqs: dictionary from (word, label) to how often the word appears\n",
    "        train_x: a list of reviews\n",
    "        train_y: a list of labels correponding to the reviews (0,1)\n",
    "    Output:\n",
    "        x: the log prior. (equation 3 above)\n",
    "        loglikelihood: the log likelihood of you Naive bayes equation. (equation 6 above)\n",
    "    '''\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "\n",
    "    # calculate V, the number of unique words in the vocabulary\n",
    "    vocab = []\n",
    "    vocab = list(freqs.keys())\n",
    "    val = list(freqs.values())\n",
    "    vocab2 = set(list(a[0] for a in freqs.keys()))\n",
    "    V = len(vocab2)\n",
    "\n",
    "    # calculate num_pos and num_neg - the total number of positive and negative words for all documents\n",
    "    num_pos = num_neg = 0\n",
    "    for a,b in freqs.keys():\n",
    "        if b == 0 : \n",
    "            num_pos += freqs[(a,b)]\n",
    "        else :\n",
    "            num_neg += freqs[(a,b)]\n",
    "        \n",
    "\n",
    "    # Calculate num_doc, the number of documents\n",
    "    num_doc = len(train_x)\n",
    "\n",
    "    # Calculate D_pos, the number of positive documents \n",
    "    pos_num_docs = len(train_y[train_y==0])\n",
    "\n",
    "    # Calculate D_neg, the number of negative documents \n",
    "    neg_num_docs = len(train_y[train_y==1])\n",
    "\n",
    "    # Calculate logprior\n",
    "    logprior = np.log(pos_num_docs/num_doc) - np.log(neg_num_docs/num_doc)\n",
    "\n",
    "    # For each word in the vocabulary...\n",
    "    for word in vocab2:\n",
    "        # get the positive and negative frequency of the word\n",
    "        if freqs.get((word , 0)) != None:\n",
    "                freq_pos = freqs[(word , 0)]\n",
    "        else: \n",
    "            freq_pos = 0\n",
    "        if freqs.get((word , 1)) != None:\n",
    "                freq_neg = freqs[(word , 1)]\n",
    "        else:\n",
    "            freq_neg = 0\n",
    "\n",
    "        # calculate the probability that each word is positive, and negative\n",
    "        p_w_pos = (freq_pos+1)/(V+num_pos)\n",
    "        p_w_neg = (freq_neg+1)/(V+num_neg)\n",
    "\n",
    "        # calculate the log likelihood of the word\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "        \n",
    "        ##NOTE - here, loglikelihood value is positive if the word is positive(sentiment). And loglikelihood is negative if the word id negative(sentiment).\n",
    "        ## The functions below have been written w.r.t this sign convention.\n",
    "        ## if we want the loglikelihood to be negative for a positive(sentiment) word, loglikelihood[word] = np.log(p_w_neg/p_w_pos)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35d14e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "75347\n"
     ]
    }
   ],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, X_train, y_train)\n",
    "print(logprior)\n",
    "print(len(loglikelihood))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61ea05",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes Predict Function\n",
    "\n",
    "The predict function outputs a 1 (negative) if the sum of the log likelihood values is greater than 0 and outputs a 0 (positive) if the sum of the log likelihood is less than or equal to 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a380ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(review, logprior, loglikelihood):\n",
    "    '''\n",
    "    Params:\n",
    "        review: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Return:\n",
    "        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    \n",
    "      # process the review to get a list of words\n",
    "    word_l = clean_review(review).split()\n",
    "\n",
    "    # initialize probability to zero\n",
    "    total_prob = 0\n",
    "\n",
    "    # add the logprior\n",
    "    total_prob = total_prob + logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            total_prob += loglikelihood[word]\n",
    "    \n",
    "    if total_prob < 0:\n",
    "        p = 1\n",
    "    else:\n",
    "        p = 0\n",
    "\n",
    "\n",
    "    return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d41e14",
   "metadata": {},
   "source": [
    "###Testing predict function on sample review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c60a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected output is 1\n"
     ]
    }
   ],
   "source": [
    "my_review = \"I thought this series was going to be another fun, action series with some dynamic plots and great performances. I was wrong. While I like Jamie Denton, this show is hardly worth watching at all, unless you enjoy watching some people brutalized and the actions of the agents supposedly warranted under the theme of national security. The show is great propaganda for the current government, and spews out jingoism as though we talk that way every day. After a couple of episodes, it was boring the hell out of me, and I started watching reruns of House Invaders on BBCAmerica instead. Rather watch CSI and Without a Trace, without a doubt.\"\n",
    "p = naive_bayes_predict(my_review, logprior, loglikelihood)\n",
    "print('The expected output is', p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb848a0d",
   "metadata": {},
   "source": [
    "## Naive Bayes Test function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec1de9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of reviews\n",
    "        test_y: the corresponding labels for the list of reviews\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
    "    \"\"\"\n",
    "    accuracy = 0  \n",
    "\n",
    "    \n",
    "    y_hats = []\n",
    "    for review in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict(review ,logprior, loglikelihood ) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 0\n",
    "\n",
    "        # append the predicted class to the list y_hats\n",
    "        print(y_hat_i)\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = np.average(np.absolute(y_hats - test_y))\n",
    "\n",
    "    accuracy = 1-error\n",
    "\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3e15ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you like original gut wrenching laughter you will like this movie. If you are young or old then y -> 0.00\n",
      "What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative  -> 1.00\n",
      "I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the -> 0.00\n",
      "Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement val -> 1.00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for review in [\"If you like original gut wrenching laughter you will like this movie. If you are young or old then you will love this movie, hell even my mom liked it.<br /><br />Great Camp!!!\",\n",
    "                \"What a waste of talent. A very poor, semi-coherent, script cripples this film. Rather unimaginative direction, too. Some VERY faint echoes of Fargo here, but it just doesn't come off.\",\n",
    "                \"I have seen this film at least 100 times and I am still excited by it, the acting is perfect and the romance between Joe and Jean keeps me on the edge of my seat, plus I still think Bryan Brown is the tops. Brilliant Film.\",\n",
    "                \"Cheap, amateurish, unimaginative, exploitative... but don't think it'll have redeeming amusement value. About as unentertaining, uninstructive and just plain dull as a film can be.\"]:\n",
    "    p = naive_bayes_predict(review, logprior, loglikelihood)\n",
    "    print(f'{review[:100]} -> {p:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2c6575",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The code in this question performs the following tasks:\n",
    "\n",
    "Data split: It splits the data into training and test sets using random selection. The user can change the training and test set by adjusting the seed parameter in the function.\n",
    "\n",
    "Model parameter calculation: Using the training set, the code calculates the parameters of the model.\n",
    "\n",
    "Confusion matrix calculation: The code prints the confusion matrix for both the training and test sets.\n",
    "\n",
    "False Positive and False Negative analysis: The code examines false positive and false negative cases and provides an explanation for why they were misclassified.\n",
    "\n",
    "The overall goal of this code is to evaluate the performance of the model on the test data and to understand the mistakes made by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2e9723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 4 CELL\n",
    "\n",
    "def naive_bayes_predict1(review, logprior, loglikelihood):\n",
    "    '''\n",
    "    Params:\n",
    "        review: a string\n",
    "        logprior: a number\n",
    "        loglikelihood: a dictionary of words mapping to numbers\n",
    "    Return:\n",
    "        total_prob: the sum of all the loglikelihoods of each word in the review (if found in the dictionary) + logprior (a number)\n",
    "\n",
    "    '''\n",
    "    \n",
    "      # process the review to get a list of words\n",
    "    word_l = clean_review(review).split()\n",
    "\n",
    "    # initialize probability to zero\n",
    "    total_prob = 0\n",
    "\n",
    "    # add the logprior\n",
    "    total_prob = total_prob + logprior\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        # check if the word exists in the loglikelihood dictionary\n",
    "        if word in loglikelihood:\n",
    "            # add the log likelihood of that word to the probability\n",
    "            total_prob += loglikelihood[word]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return total_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3ac8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C6 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def test_naive_bayes_conf(test_x, test_y, logprior, loglikelihood):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        test_x: A list of reviews\n",
    "        test_y: the corresponding labels for the list of reviews\n",
    "        logprior: the logprior\n",
    "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
    "    Output:\n",
    "        accuracy: (# of reviews classified correctly)/(total # of reviews)\n",
    "    \"\"\"\n",
    "    accuracy = 0  \n",
    "\n",
    "    y_hats = []\n",
    "    for review in test_x:\n",
    "        # if the prediction is > 0\n",
    "        if naive_bayes_predict1(review ,logprior, loglikelihood ) > 0:\n",
    "            # the predicted class is 1\n",
    "            y_hat_i = 0\n",
    "        else:\n",
    "            # otherwise the predicted class is 0\n",
    "            y_hat_i = 1\n",
    "        \n",
    "        # append the predicted class to the list y_hats\n",
    "        #print(y_hat_i)\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    # error is the average of the absolute values of the differences between y_hats and test_y\n",
    "    error = np.average(np.absolute(y_hats - test_y))\n",
    "    accuracy = 1-error\n",
    "    print(\"accuracy = \" , accuracy)\n",
    "    data_conf = {'y_actual':  test_y  , 'y_predicted': y_hats}\n",
    "    df_conf = pd.DataFrame(data_conf)\n",
    "    confusion_matrix1 = pd.crosstab(df_conf['y_actual'], df_conf['y_predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    print(\"confusion_matrix = \" )\n",
    "    print(confusion_matrix1)\n",
    "    \n",
    "    print()\n",
    "    return confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b5cb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def split_data(seed):\n",
    "    X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(df_upsampled['review'], df_upsampled['sentiment'] , random_state=seed)\n",
    "    output_map = {'positive': 0, 'negative': 1}\n",
    "    y_train_new = y_train_new.map(output_map)\n",
    "    y_test_new = y_test_new.map(output_map)\n",
    "    freqs = review_counter({}, X_train_new, y_train_new)\n",
    "    logprior_new, loglikelihood_new = train_naive_bayes(freqs, X_train_new, y_train_new )\n",
    "    print(\"log prior = \" , str(round(logprior_new, 2)))\n",
    "    print(\"loglikelihood = \", len(loglikelihood_new))\n",
    "    conf = test_naive_bayes_conf(X_test_new,y_test_new,logprior_new ,loglikelihood_new)\n",
    "    #print(conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ee1a1234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log prior =  -0.0\n",
      "loglikelihood =  72919\n",
      "accuracy =  0.8731762065095399\n",
      "confusion_matrix = \n",
      "Predicted     0     1\n",
      "Actual               \n",
      "0          2607   519\n",
      "1           272  2839\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split_data(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7596d2d",
   "metadata": {},
   "source": [
    "Precision = TruePositives / (TruePositives + FalsePositives)  = 2607/(2607+ 272) = 0.905\n",
    "\n",
    "Recall = TruePositives / (TruePositives + FalseNegatives) = 2607/(2607+519) = 0.834\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25bb7e",
   "metadata": {},
   "source": [
    "4. In the above data, misclassification has occured because there may be words in the review that were more used in the opposite sentiment reviews in the test data. Because of this, the likelihood of the term in the opposite sentiment was higher. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
